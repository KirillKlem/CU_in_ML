{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path, PurePath\n",
    "\n",
    "# Third-party library imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.io import gfile\n",
    "from scipy.fftpack import dct\n",
    "from scipy.spatial.distance import cosine, euclidean\n",
    "import moviepy.video.io.VideoFileClip as mp\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Segmentation Models PyTorch import\n",
    "import segmentation_models_pytorch as smp"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T02:43:00.812208700Z",
     "start_time": "2024-09-29T02:43:00.796577400Z"
    }
   },
   "id": "945e070237f04cd9"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\yappy\\test_dataset_test_data_yappy\\test_data_yappy\\test_dataset\\49577a11-51b9-490a-b1f0-df17335219de.mp4\n",
      "C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\yappy\\test_dataset_test_data_yappy\\test_data_yappy\\test_dataset\\da9783ba-ceac-47ed-9d8f-30b614e938dd.mp4\n"
     ]
    }
   ],
   "source": [
    "test_video = r'C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\yappy\\test_dataset_test_data_yappy\\test_data_yappy\\test_dataset\\49577a11-51b9-490a-b1f0-df17335219de.mp4'\n",
    "test_video2 = r'C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\yappy\\test_dataset_test_data_yappy\\test_data_yappy\\test_dataset\\da9783ba-ceac-47ed-9d8f-30b614e938dd.mp4'\n",
    "print(test_video)\n",
    "print(test_video2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T02:40:35.509429700Z",
     "start_time": "2024-09-29T02:40:35.497923900Z"
    }
   },
   "id": "189ce9825d6dce36"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "class ResNetEncoder():\n",
    "    def __init__(self):\n",
    "        self.model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "    # 1. Извлечение кадров из видео\n",
    "    def extract_frames(self, video_path, max_frames=10):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frames = []\n",
    "        success, frame = cap.read()\n",
    "        count = 0\n",
    "        while success and count < max_frames:\n",
    "            frames.append(frame)\n",
    "            success, frame = cap.read()\n",
    "            count += 1\n",
    "        cap.release()\n",
    "        return frames\n",
    "\n",
    "    # 2. Извлечение гистограммы цветов\n",
    "    def extract_color_histogram(self, frame):\n",
    "        hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        hist = cv2.calcHist([hsv_frame], [0, 1, 2], None, [50, 60, 70], [0, 180, 0, 256, 0, 256])\n",
    "        hist = cv2.normalize(hist, hist).flatten()\n",
    "        return hist\n",
    "\n",
    "    # 3. Извлечение признаков с помощью предобученной модели ResNet50\n",
    "    def extract_deep_features(self, frame):\n",
    "        frame_resized = cv2.resize(frame, (224, 224))\n",
    "        frame_preprocessed = preprocess_input(np.expand_dims(frame_resized, axis=0))\n",
    "        features = self.model.predict(frame_preprocessed, verbose=0)\n",
    "        return features.flatten()\n",
    "\n",
    "    # 4. Комбинирование всех признаков (гистограмма цветов, ResNet, ORB)\n",
    "    def extract_combined_features(self, frame):\n",
    "        color_hist = self.extract_color_histogram(frame)\n",
    "        deep_features = self.extract_deep_features(frame)\n",
    "\n",
    "        # Объединение всех признаков в один вектор\n",
    "        combined_features = np.hstack((color_hist, deep_features))\n",
    "        return combined_features\n",
    "\n",
    "    # 5. Извлечение кадров из видео и получение средних признаков\n",
    "    def encode(self, video_path, max_frames=10):\n",
    "        frames = self.extract_frames(video_path, max_frames)\n",
    "        combined_features_list = [self.extract_combined_features(frame) for frame in frames]\n",
    "\n",
    "        # Усредняем признаки по кадрам\n",
    "        average_features = np.mean(combined_features_list, axis=0)\n",
    "        return average_features\n",
    "\n",
    "    def get_distance(self, emb1, emb2):\n",
    "        similarity = 1 - cosine(emb1, emb2)\n",
    "        return similarity"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T02:58:35.199551200Z",
     "start_time": "2024-09-29T02:58:35.183774900Z"
    }
   },
   "id": "5a505774418e4a2a"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "ResNetEnc = ResNetEncoder()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T02:58:36.917025300Z",
     "start_time": "2024-09-29T02:58:36.227702300Z"
    }
   },
   "id": "d7dfd79bc7d01efa"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9795281887054443"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb1 = ResNetEnc.encode(test_video)\n",
    "emb2 = ResNetEnc.encode(test_video2)\n",
    "ResNetEnc.get_distance(emb1, emb2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T02:58:40.805880600Z",
     "start_time": "2024-09-29T02:58:38.312456100Z"
    }
   },
   "id": "4e502e5ac9b5a854"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "class InceptionEncoder():\n",
    "    def __init__(self):\n",
    "        self.model = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "    def frames_extract(self, video_file, start_off=0, sampling_fps=1, max_frame_cnt=60):\n",
    "        \"\"\"Extracts frames from input video.\"\"\"\n",
    "        if not os.path.exists(video_file):\n",
    "            return None\n",
    "\n",
    "        vcap = cv2.VideoCapture(video_file)\n",
    "        fps = vcap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_interval = int(fps / sampling_fps) if sampling_fps > 0 and sampling_fps < fps else 1\n",
    "        frame_list, cnt = [], 0\n",
    "\n",
    "        success, im = vcap.read()\n",
    "        while success and cnt < max_frame_cnt:\n",
    "            if cnt % frame_interval == 0:\n",
    "                frame_list.append(im)\n",
    "            cnt += 1\n",
    "            success, im = vcap.read()\n",
    "\n",
    "        return np.array(frame_list) if frame_list else None\n",
    "\n",
    "    def feature_from_single_image_file(self, image_file):\n",
    "        \"\"\"Extract feature vector from a single image file.\"\"\"\n",
    "        if not gfile.exists(image_file):\n",
    "            print(f\"File does not exist: {image_file}\")\n",
    "            return None\n",
    "\n",
    "        image_data = gfile.GFile(image_file, 'rb').read()\n",
    "        image_tensor = tf.image.decode_jpeg(image_data, channels=3)\n",
    "        image_tensor = tf.image.resize(image_tensor, (299, 299))  # Inception-v3 input size\n",
    "\n",
    "        image_tensor = tf.expand_dims(image_tensor, axis=0)\n",
    "        image_tensor = image_tensor / 255.0\n",
    "\n",
    "        print(self.model.signatures['serving_default'](image_tensor))\n",
    "        feature_tensor = self.model.signatures['serving_default'](image_tensor)['pool_3']\n",
    "        return np.squeeze(feature_tensor.numpy())\n",
    "\n",
    "    def feature_from_single_video_file(self, video_file, start_off=0, sampling_fps=1, max_frame_cnt=60, padding=True):\n",
    "        \"\"\"Extract feature vectors from a video file.\"\"\"\n",
    "        if not gfile.exists(video_file):\n",
    "            print(f\"File does not exist: {video_file}\")\n",
    "            return None\n",
    "\n",
    "        frames = self.frames_extract(video_file, start_off, sampling_fps, max_frame_cnt)\n",
    "        if frames is None:\n",
    "            return None\n",
    "\n",
    "        features = []\n",
    "        for frame in frames:\n",
    "            frame_tensor = tf.convert_to_tensor(frame, dtype=tf.uint8)\n",
    "            frame_tensor = tf.image.resize(frame_tensor, (299, 299))  # Inception-v3 input size\n",
    "            frame_tensor = tf.expand_dims(frame_tensor, axis=0)\n",
    "            frame_tensor = frame_tensor / 255.0\n",
    "\n",
    "            # Получаем эмбеддинги напрямую через вызов модели\n",
    "            feature_tensor = self.model(frame_tensor)\n",
    "            features.append(np.squeeze(feature_tensor.numpy()))\n",
    "\n",
    "        # Padding if necessary\n",
    "        if padding and max_frame_cnt > len(features):\n",
    "            zero_feat = np.zeros([2048], dtype=np.float32)\n",
    "            features.extend([zero_feat] * (max_frame_cnt - len(features)))\n",
    "\n",
    "        return np.array(features)\n",
    "\n",
    "    def encode(self, video_path):\n",
    "        video_features = self.feature_from_single_video_file(video_path, sampling_fps=1, max_frame_cnt=60, padding=True)\n",
    "        mean_features = np.mean(video_features, axis=0)\n",
    "        return mean_features\n",
    "\n",
    "    def get_distance(self, emb1, emb2):\n",
    "        similarity = cosine_similarity([emb1], [emb2])[0][0]\n",
    "        return similarity\n",
    "\n",
    "    def get_evc_distance(self, emb1, emb2):\n",
    "        similarity = euclidean(emb1, emb2)\n",
    "        return similarity"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T03:46:10.842770100Z",
     "start_time": "2024-09-29T03:46:10.780108400Z"
    }
   },
   "id": "3bb01940fe144542"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.00658599, 0.00709436, 0.00497256, ..., 0.01663911, 0.01624956,\n       0.00550472], dtype=float32)"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InceptionEnc = InceptionEncoder()\n",
    "InceptionEnc.encode(test_video)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T03:46:25.198096200Z",
     "start_time": "2024-09-29T03:46:22.077018500Z"
    }
   },
   "id": "ec602740862ac30"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "0.18608391284942627"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb1 = InceptionEnc.encode(test_video)\n",
    "emb2 = InceptionEnc.encode(test_video2)\n",
    "InceptionEnc.get_evc_distance(emb1, emb2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T03:46:39.569544600Z",
     "start_time": "2024-09-29T03:46:36.535518400Z"
    }
   },
   "id": "e8377ec8153abcf6"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "class AudioEncoder():\n",
    "    def encode(self, video_path):\n",
    "        video = mp.VideoFileClip(video_path)\n",
    "        if video.audio is None:\n",
    "            print(video_path)\n",
    "            return np.zeros((128,))\n",
    "        video.audio.write_audiofile(\"audio1.wav\")\n",
    "        y1, sr1 = librosa.load(\"audio1.wav\", sr=None)\n",
    "        S1 = librosa.feature.melspectrogram(y=y1, sr=sr1)\n",
    "        mean_spectrum1 = np.mean(S1, axis=1)\n",
    "        return mean_spectrum1\n",
    "\n",
    "    def get_distance(self, spect1, spect2):\n",
    "        similarity = 1 - cosine(spect1, spect2)\n",
    "        return similarity"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T03:16:06.286128200Z",
     "start_time": "2024-09-29T03:16:06.270364700Z"
    }
   },
   "id": "eeee2a6f05546946"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in audio1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in audio1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "(128,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": "0.7156458497047424"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AudioEnc = AudioEncoder()\n",
    "emb1 = AudioEnc.encode(test_video)\n",
    "emb2 = AudioEnc.encode(test_video2)\n",
    "print(emb1.shape)\n",
    "AudioEnc.get_distance(emb1, emb2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T03:16:18.878653900Z",
     "start_time": "2024-09-29T03:16:18.263775Z"
    }
   },
   "id": "728c750ffcecdc29"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "class UnetEncoder():\n",
    "    def __init__(self):\n",
    "        self.transform = transforms.Compose([transforms.Resize((256, 256))])\n",
    "        unet_model = smp.Unet(\n",
    "            encoder_name=\"resnet34\",\n",
    "            encoder_weights=\"imagenet\",\n",
    "            in_channels=3,\n",
    "            classes=1\n",
    "        )\n",
    "        self.encoder = unet_model.encoder\n",
    "\n",
    "    def frames_extract(self, video_file, sampling_fps=1, max_frame_cnt=60):\n",
    "        \"\"\"Извлекает кадры из видео с использованием OpenCV.\"\"\"\n",
    "        vcap = cv2.VideoCapture(video_file)\n",
    "        fps = vcap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_interval = int(fps / sampling_fps)\n",
    "        frames = []\n",
    "\n",
    "        success, frame = vcap.read()\n",
    "        count = 0\n",
    "\n",
    "        while success and count < max_frame_cnt:\n",
    "            if count % frame_interval == 0:\n",
    "                frames.append(frame)\n",
    "            success, frame = vcap.read()\n",
    "            count += 1\n",
    "\n",
    "        vcap.release()\n",
    "        return frames\n",
    "\n",
    "    def encode(self, video_path):\n",
    "        frames = self.frames_extract(video_path)\n",
    "        features = []\n",
    "\n",
    "        for frame in frames:\n",
    "            frame_tensor = self.transform(torch.Tensor(frame).permute(2, 0, 1)).unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                feature = self.encoder(frame_tensor)[-1]  # Берем последний слой энкодера\n",
    "            features.append(feature.squeeze(0))\n",
    "\n",
    "        # Усредняем признаки по всем кадрам\n",
    "        return torch.mean(torch.stack(features), dim=0)\n",
    "\n",
    "    def get_distance(self, feature1, feature2):\n",
    "        cosine_sim = F.cosine_similarity(feature1.view(1, -1), feature2.view(1, -1))\n",
    "        return 1 - cosine_sim.item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T02:35:23.163647600Z",
     "start_time": "2024-09-29T02:35:23.132340Z"
    }
   },
   "id": "e8105cf86b9f43d4"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to C:\\Users\\Vladimir/.cache\\torch\\hub\\checkpoints\\resnet34-333f7ec4.pth\n",
      "100%|██████████| 83.3M/83.3M [00:18<00:00, 4.72MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.2974700927734375"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UnetEnc = UnetEncoder()\n",
    "emb1 = UnetEnc.encode(test_video)\n",
    "emb2 = UnetEnc.encode(test_video2)\n",
    "UnetEnc.get_distance(emb1, emb2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T02:36:05.280984300Z",
     "start_time": "2024-09-29T02:35:45.546537200Z"
    }
   },
   "id": "acb9bc5752720a51"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "class LengthEncoder:\n",
    "    def encode(self, video_file):\n",
    "        cap = cv2.VideoCapture(video_file)\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)  # Количество кадров в секунду\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Общее количество кадров\n",
    "        cap.release()\n",
    "        if fps > 0:  # Если fps корректный, считаем длину\n",
    "            video_length = frame_count / fps  # Длина видео в секундах\n",
    "        else:\n",
    "            video_length = 0  # Если fps не найден, длина видео = 0\n",
    "        return video_length\n",
    "\n",
    "    # Функция для расчета длины видео и их соотношения\n",
    "    def get_distance(self, length_1, length_2):\n",
    "        length_diff = abs(length_1 - length_2)\n",
    "        max_length = max(length_1, length_2)\n",
    "\n",
    "        # Избегаем деления на 0\n",
    "        if max_length > 0:\n",
    "            length_ratio = length_diff / max_length\n",
    "        else:\n",
    "            length_ratio = 0\n",
    "\n",
    "        return length_ratio"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T03:42:56.648158600Z",
     "start_time": "2024-09-29T03:42:56.585502900Z"
    }
   },
   "id": "becd1cac581fe493"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "0.0"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LengthEnc = LengthEncoder()\n",
    "emb1 = LengthEnc.encode(test_video)\n",
    "emb2 = LengthEnc.encode(test_video2)\n",
    "LengthEnc.get_distance(emb1, emb2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T03:43:09.059886400Z",
     "start_time": "2024-09-29T03:43:09.028483700Z"
    }
   },
   "id": "28ddf349df6234fd"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "               created                                  uuid  \\\n0  2024-06-01 01:37:57  49577a11-51b9-490a-b1f0-df17335219de   \n1  2024-06-01 04:42:10  4e1f7fad-5008-4216-9849-550a00f1e35f   \n2  2024-06-01 08:44:48  337fdbe6-2bc7-4bc7-931e-d94ada927ede   \n3  2024-06-01 10:11:48  35138a88-0249-405e-91b4-8a36b1e2e730   \n4  2024-06-01 12:23:29  322f4312-3d46-401b-8cd9-80a0d06347ed   \n\n                                                link  \n0  https://s3.ritm.media/yappy-db-duplicates/4957...  \n1  https://s3.ritm.media/yappy-db-duplicates/4e1f...  \n2  https://s3.ritm.media/yappy-db-duplicates/337f...  \n3  https://s3.ritm.media/yappy-db-duplicates/3513...  \n4  https://s3.ritm.media/yappy-db-duplicates/322f...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>created</th>\n      <th>uuid</th>\n      <th>link</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2024-06-01 01:37:57</td>\n      <td>49577a11-51b9-490a-b1f0-df17335219de</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/4957...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2024-06-01 04:42:10</td>\n      <td>4e1f7fad-5008-4216-9849-550a00f1e35f</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/4e1f...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2024-06-01 08:44:48</td>\n      <td>337fdbe6-2bc7-4bc7-931e-d94ada927ede</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/337f...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2024-06-01 10:11:48</td>\n      <td>35138a88-0249-405e-91b4-8a36b1e2e730</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/3513...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2024-06-01 12:23:29</td>\n      <td>322f4312-3d46-401b-8cd9-80a0d06347ed</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/322f...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test_dataset_test_data_yappy/test_data_yappy/test.csv')\n",
    "# test = pd.read_csv('test_clean.csv')\n",
    "test.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [10:55<00:00,  1.53it/s]\n"
     ]
    }
   ],
   "source": [
    "path_to_test_data = r'C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\yappy\\test_dataset_test_data_yappy\\test_data_yappy\\test_dataset'\n",
    "\n",
    "test['video_path'] = test['uuid'].apply(lambda uuid: f\"{path_to_test_data}\\\\{uuid}.mp4\")\n",
    "tqdm.pandas()\n",
    "test['embeddings'] = test['video_path'].progress_apply(InceptionEnc.encode)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T02:54:01.355562600Z",
     "start_time": "2024-09-29T02:43:06.035773400Z"
    }
   },
   "id": "2097020254c7cb95"
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "n = test.shape[0]\n",
    "test['is_duplicate'] = [False] * n\n",
    "test['duplicate_for'] = [np.nan] * n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T04:22:03.002993500Z",
     "start_time": "2024-09-29T04:22:02.937772500Z"
    }
   },
   "id": "e1e2335d924dfdc"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "               created                                  uuid  \\\n0  2024-06-01 01:37:57  49577a11-51b9-490a-b1f0-df17335219de   \n1  2024-06-01 04:42:10  4e1f7fad-5008-4216-9849-550a00f1e35f   \n2  2024-06-01 08:44:48  337fdbe6-2bc7-4bc7-931e-d94ada927ede   \n3  2024-06-01 10:11:48  35138a88-0249-405e-91b4-8a36b1e2e730   \n4  2024-06-01 12:23:29  322f4312-3d46-401b-8cd9-80a0d06347ed   \n\n                                                link  \\\n0  https://s3.ritm.media/yappy-db-duplicates/4957...   \n1  https://s3.ritm.media/yappy-db-duplicates/4e1f...   \n2  https://s3.ritm.media/yappy-db-duplicates/337f...   \n3  https://s3.ritm.media/yappy-db-duplicates/3513...   \n4  https://s3.ritm.media/yappy-db-duplicates/322f...   \n\n                                          video_path  \\\n0  C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...   \n1  C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...   \n2  C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...   \n3  C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...   \n4  C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...   \n\n                                          embeddings  is_duplicate  \\\n0  [0.0065859933, 0.0070943553, 0.0049725627, 0.0...         False   \n1  [0.013478812, 0.01082532, 0.027198287, 0.00505...         False   \n2  [0.003774149, 0.004182019, 0.0034305027, 0.014...         False   \n3  [0.0074166446, 0.010031568, 0.02124418, 0.0043...         False   \n4  [0.0141136665, 0.03179764, 0.034023765, 0.0206...         False   \n\n   duplicate_for  \n0            NaN  \n1            NaN  \n2            NaN  \n3            NaN  \n4            NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>created</th>\n      <th>uuid</th>\n      <th>link</th>\n      <th>video_path</th>\n      <th>embeddings</th>\n      <th>is_duplicate</th>\n      <th>duplicate_for</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2024-06-01 01:37:57</td>\n      <td>49577a11-51b9-490a-b1f0-df17335219de</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/4957...</td>\n      <td>C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...</td>\n      <td>[0.0065859933, 0.0070943553, 0.0049725627, 0.0...</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2024-06-01 04:42:10</td>\n      <td>4e1f7fad-5008-4216-9849-550a00f1e35f</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/4e1f...</td>\n      <td>C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...</td>\n      <td>[0.013478812, 0.01082532, 0.027198287, 0.00505...</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2024-06-01 08:44:48</td>\n      <td>337fdbe6-2bc7-4bc7-931e-d94ada927ede</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/337f...</td>\n      <td>C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...</td>\n      <td>[0.003774149, 0.004182019, 0.0034305027, 0.014...</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2024-06-01 10:11:48</td>\n      <td>35138a88-0249-405e-91b4-8a36b1e2e730</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/3513...</td>\n      <td>C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...</td>\n      <td>[0.0074166446, 0.010031568, 0.02124418, 0.0043...</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2024-06-01 12:23:29</td>\n      <td>322f4312-3d46-401b-8cd9-80a0d06347ed</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/322f...</td>\n      <td>C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...</td>\n      <td>[0.0141136665, 0.03179764, 0.034023765, 0.0206...</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T02:55:03.027394600Z",
     "start_time": "2024-09-29T02:55:03.011762100Z"
    }
   },
   "id": "f100623f7a7f892a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ResNetEnc"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89e55234733d4760"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:41<00:00,  4.51it/s]\n"
     ]
    }
   ],
   "source": [
    "test['UnetEnc_embeddings'] = test['video_path'].progress_apply(UnetEnc.encode)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T03:06:05.214916300Z",
     "start_time": "2024-09-29T03:02:23.577712500Z"
    }
   },
   "id": "b4817fef42ec05f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test['AudioEnc_embeddings'] = test['video_path'].apply(AudioEnc.encode)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "675dfca4e753e4ca"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 100.31it/s]\n"
     ]
    }
   ],
   "source": [
    "test['length'] = test['video_path'].progress_apply(LengthEnc.encode)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T03:23:18.594918800Z",
     "start_time": "2024-09-29T03:23:08.610067Z"
    }
   },
   "id": "39e0ba05e4c920fd"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "test.to_csv('test_embeddings.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T03:24:50.406205700Z",
     "start_time": "2024-09-29T03:24:48.491639300Z"
    }
   },
   "id": "dda77a835b7227b6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2e87e27bf3c410ef"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "NearestNeighbors(metric='cosine', n_neighbors=3)",
      "text/html": "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=3)</pre></div></div></div></div></div>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "embeddings_matrix = np.stack(test['embeddings'].values)\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=5, metric='cosine')  # Можно выбрать метрику (например, 'euclidean')\n",
    "knn.fit(embeddings_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T03:25:02.887096300Z",
     "start_time": "2024-09-29T03:25:02.871434100Z"
    }
   },
   "id": "6181415adeb49c41"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'models/linear_model.pickle'\n",
    "\n",
    "with open(filename, 'rb') as file:\n",
    "    lr = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T03:51:06.243708700Z",
     "start_time": "2024-09-29T03:51:06.227123400Z"
    }
   },
   "id": "c1cbca1e13c41ec4"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "test['created'] = pd.to_datetime(test['created'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T04:24:35.802247600Z",
     "start_time": "2024-09-29T04:24:35.782510Z"
    }
   },
   "id": "f85b7ace600c634f"
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for index, row1 in test.iterrows():\n",
    "    if index < 5: continue\n",
    "\n",
    "    distances, indices = knn.kneighbors([row1['embeddings']])\n",
    "    # Получение информации о самых похожих видео\n",
    "    nearest_videos = test.iloc[indices[0]]\n",
    "    uuids = nearest_videos['uuid']\n",
    "    nearest_distances = distances[0]\n",
    "\n",
    "    cur_metrics = nearest_videos[['created', 'uuid', 'embeddings', 'AudioEnc_embeddings', 'UnetEnc_embeddings', 'length']]\n",
    "\n",
    "    first_row = cur_metrics.iloc[0]\n",
    "    \n",
    "    # Создаем список для хранения новых строк\n",
    "    new_rows = []\n",
    "\n",
    "    # Проходим по всем строкам, начиная со второй\n",
    "    for _, row in cur_metrics.iloc[1:].iterrows():\n",
    "        new_row = {\n",
    "            'created': row['created'],\n",
    "            'uuid': row['uuid'],\n",
    "            'Inception_cosin': InceptionEnc.get_distance(first_row['embeddings'], row['embeddings']),\n",
    "            'Inception_eucld': InceptionEnc.get_evc_distance(first_row['embeddings'], row['embeddings']),\n",
    "            'audio': AudioEnc.get_distance(first_row['AudioEnc_embeddings'], row['AudioEnc_embeddings']),\n",
    "            'UNet': UnetEnc.get_distance(first_row['UnetEnc_embeddings'], row['UnetEnc_embeddings']),\n",
    "            'length_ratio': LengthEnc.get_distance(first_row['length'], row['length'])\n",
    "        }\n",
    "        new_rows.append(new_row)\n",
    "\n",
    "    # Создаем новый DataFrame из списка новых строк\n",
    "    new_df = pd.DataFrame(new_rows)\n",
    "    preds = lr.predict(new_df.iloc[:, 2:])\n",
    "    preds_proba = lr.predict_proba(new_df.iloc[:, 2:])[:, 1]\n",
    "    new_df['is_dub'] = preds\n",
    "    new_df['is_dub_proba'] = preds_proba\n",
    "    # print(new_df)\n",
    "    \n",
    "    dubs = new_df[new_df['is_dub'] == 1].sort_values('is_dub_proba', ascending=False)\n",
    "    \n",
    "    for i, r in dubs.iterrows():\n",
    "        if r['created'] > row1['created']:\n",
    "            test.loc[test['uuid'] == r['uuid'], 'is_duplicate'] = True\n",
    "            test.loc[test['uuid'] == r['uuid'], 'duplicate_for'] = row1['uuid']\n",
    "                    \n",
    "    if index % 50 == 0:\n",
    "        print(index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T04:27:36.293877100Z",
     "start_time": "2024-09-29T04:27:13.876527500Z"
    }
   },
   "id": "8690c01478392fa6"
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "              created                                  uuid  \\\n0 2024-06-01 01:37:57  49577a11-51b9-490a-b1f0-df17335219de   \n1 2024-06-01 04:42:10  4e1f7fad-5008-4216-9849-550a00f1e35f   \n2 2024-06-01 08:44:48  337fdbe6-2bc7-4bc7-931e-d94ada927ede   \n3 2024-06-01 10:11:48  35138a88-0249-405e-91b4-8a36b1e2e730   \n4 2024-06-01 12:23:29  322f4312-3d46-401b-8cd9-80a0d06347ed   \n\n                                                link  \\\n0  https://s3.ritm.media/yappy-db-duplicates/4957...   \n1  https://s3.ritm.media/yappy-db-duplicates/4e1f...   \n2  https://s3.ritm.media/yappy-db-duplicates/337f...   \n3  https://s3.ritm.media/yappy-db-duplicates/3513...   \n4  https://s3.ritm.media/yappy-db-duplicates/322f...   \n\n                                          video_path  \\\n0  C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...   \n1  C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...   \n2  C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...   \n3  C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...   \n4  C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...   \n\n                                          embeddings  is_duplicate  \\\n0  [0.0065859933, 0.0070943553, 0.0049725627, 0.0...         False   \n1  [0.013478812, 0.01082532, 0.027198287, 0.00505...         False   \n2  [0.003774149, 0.004182019, 0.0034305027, 0.014...         False   \n3  [0.0074166446, 0.010031568, 0.02124418, 0.0043...         False   \n4  [0.0141136665, 0.03179764, 0.034023765, 0.0206...         False   \n\n  duplicate_for                                 UnetEnc_embeddings  \\\n0           NaN  [[[tensor(0.), tensor(0.), tensor(0.), tensor(...   \n1           NaN  [[[tensor(0.), tensor(0.), tensor(0.2252), ten...   \n2           NaN  [[[tensor(0.), tensor(0.), tensor(0.), tensor(...   \n3           NaN  [[[tensor(0.), tensor(0.), tensor(0.2406), ten...   \n4           NaN  [[[tensor(0.), tensor(0.0939), tensor(0.0783),...   \n\n                                 AudioEnc_embeddings     length  \n0  [0.00041812917, 0.000780223, 0.0034573867, 0.0...  16.000000  \n1  [9.353134, 19.390526, 7.0610957, 5.4561687, 4....  56.250000  \n2  [6.0818267, 48.76453, 40.668804, 23.965372, 37...  18.966667  \n3  [110.40445, 477.3407, 260.7453, 82.90226, 48.8...   7.833333  \n4  [90.45213, 65.43523, 21.771788, 19.703815, 23....  23.666667  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>created</th>\n      <th>uuid</th>\n      <th>link</th>\n      <th>video_path</th>\n      <th>embeddings</th>\n      <th>is_duplicate</th>\n      <th>duplicate_for</th>\n      <th>UnetEnc_embeddings</th>\n      <th>AudioEnc_embeddings</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2024-06-01 01:37:57</td>\n      <td>49577a11-51b9-490a-b1f0-df17335219de</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/4957...</td>\n      <td>C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...</td>\n      <td>[0.0065859933, 0.0070943553, 0.0049725627, 0.0...</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>[[[tensor(0.), tensor(0.), tensor(0.), tensor(...</td>\n      <td>[0.00041812917, 0.000780223, 0.0034573867, 0.0...</td>\n      <td>16.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2024-06-01 04:42:10</td>\n      <td>4e1f7fad-5008-4216-9849-550a00f1e35f</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/4e1f...</td>\n      <td>C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...</td>\n      <td>[0.013478812, 0.01082532, 0.027198287, 0.00505...</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>[[[tensor(0.), tensor(0.), tensor(0.2252), ten...</td>\n      <td>[9.353134, 19.390526, 7.0610957, 5.4561687, 4....</td>\n      <td>56.250000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2024-06-01 08:44:48</td>\n      <td>337fdbe6-2bc7-4bc7-931e-d94ada927ede</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/337f...</td>\n      <td>C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...</td>\n      <td>[0.003774149, 0.004182019, 0.0034305027, 0.014...</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>[[[tensor(0.), tensor(0.), tensor(0.), tensor(...</td>\n      <td>[6.0818267, 48.76453, 40.668804, 23.965372, 37...</td>\n      <td>18.966667</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2024-06-01 10:11:48</td>\n      <td>35138a88-0249-405e-91b4-8a36b1e2e730</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/3513...</td>\n      <td>C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...</td>\n      <td>[0.0074166446, 0.010031568, 0.02124418, 0.0043...</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>[[[tensor(0.), tensor(0.), tensor(0.2406), ten...</td>\n      <td>[110.40445, 477.3407, 260.7453, 82.90226, 48.8...</td>\n      <td>7.833333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2024-06-01 12:23:29</td>\n      <td>322f4312-3d46-401b-8cd9-80a0d06347ed</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/322f...</td>\n      <td>C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...</td>\n      <td>[0.0141136665, 0.03179764, 0.034023765, 0.0206...</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>[[[tensor(0.), tensor(0.0939), tensor(0.0783),...</td>\n      <td>[90.45213, 65.43523, 21.771788, 19.703815, 23....</td>\n      <td>23.666667</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T04:27:54.180152900Z",
     "start_time": "2024-09-29T04:27:47.788131500Z"
    }
   },
   "id": "3af40a96a3937725"
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "                created                                  uuid  \\\n42  2024-06-05 01:53:00  fd52cbe5-012f-4451-abad-1c86c8279e8c   \n50  2024-06-05 19:13:01  6f6f5da8-f997-491d-8fe0-64d262b2ee4c   \n60  2024-06-06 10:04:01  cbf3948e-e8a0-4e61-858d-72b7ff2d2d43   \n63  2024-06-06 13:46:37  89fca4ee-4678-482b-8d6d-907dbc057151   \n79  2024-06-07 22:14:03  51b077bc-fac3-4cdb-bda4-06cd60d53af7   \n..                  ...                                   ...   \n993 2024-09-07 06:04:07  7e67cde3-d548-4e7b-b3e1-90c83a4632ed   \n995 2024-09-07 17:10:54  933149f9-e660-4377-95c8-f8dd329db24e   \n996 2024-09-08 05:18:24  9f707190-3b32-48bf-a5f4-ceec6eedb847   \n998 2024-09-11 04:42:01  ef7e175e-2391-45a0-b69f-33837668bb79   \n999 2024-09-12 22:21:33  7ed53812-357f-4ad4-bccc-39bb63e27ccb   \n\n                                                  link  \\\n42   https://s3.ritm.media/yappy-db-duplicates/fd52...   \n50   https://s3.ritm.media/yappy-db-duplicates/6f6f...   \n60   https://s3.ritm.media/yappy-db-duplicates/cbf3...   \n63   https://s3.ritm.media/yappy-db-duplicates/89fc...   \n79   https://s3.ritm.media/yappy-db-duplicates/51b0...   \n..                                                 ...   \n993  https://s3.ritm.media/yappy-db-duplicates/7e67...   \n995  https://s3.ritm.media/yappy-db-duplicates/9331...   \n996  https://s3.ritm.media/yappy-db-duplicates/9f70...   \n998  https://s3.ritm.media/yappy-db-duplicates/ef7e...   \n999  https://s3.ritm.media/yappy-db-duplicates/7ed5...   \n\n                                            video_path  \\\n42   C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...   \n50   C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...   \n60   C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...   \n63   C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...   \n79   C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...   \n..                                                 ...   \n993  C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...   \n995  C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...   \n996  C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...   \n998  C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...   \n999  C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...   \n\n                                            embeddings  is_duplicate  \\\n42   [0.0040277336, 0.013641495, 0.007854927, 0.025...          True   \n50   [0.028689208, 0.0125948135, 0.005007297, 0.003...          True   \n60   [0.0054139197, 0.009174943, 0.015418697, 0.002...          True   \n63   [0.00235023, 0.0231305, 0.005213861, 0.0035420...          True   \n79   [0.0065238466, 0.002718225, 0.0021864201, 0.01...          True   \n..                                                 ...           ...   \n993  [0.008075179, 0.016512446, 0.035428133, 0.0115...          True   \n995  [0.015765151, 0.007593849, 0.03509754, 0.01167...          True   \n996  [0.042089663, 0.0043040505, 0.023805328, 0.012...          True   \n998  [0.006182716, 0.019054323, 0.032745354, 0.0131...          True   \n999  [0.016747646, 0.003939935, 0.010330777, 0.0043...          True   \n\n                            duplicate_for  \\\n42   4b005e08-6890-4c4b-b0cf-95dc3e1aabeb   \n50   22ee80a3-d9ef-48d4-83d7-9c97cc7030c2   \n60   045265e5-0d4c-4372-b960-3087f685eb97   \n63   2cfd6af3-7df6-4afa-8c3b-c17236c83c03   \n79   0d62849b-d3b9-47af-a285-2f638bc9ac13   \n..                                    ...   \n993  4b06ed60-3d36-4537-b351-be9dd28755b7   \n995  06e0d485-d4e1-4ba7-8eb2-e2f1fcfca416   \n996  56cfa0d5-a050-4443-9a80-1403bcad6839   \n998  0574335c-9884-40de-a514-97b3fd3d72df   \n999  3c07e9ae-1796-4bcd-8b12-1ef8a9b61fd5   \n\n                                    UnetEnc_embeddings  \\\n42   [[[tensor(0.), tensor(0.0393), tensor(0.2136),...   \n50   [[[tensor(0.), tensor(0.), tensor(1.4099), ten...   \n60   [[[tensor(0.), tensor(0.), tensor(0.), tensor(...   \n63   [[[tensor(0.), tensor(0.), tensor(0.1531), ten...   \n79   [[[tensor(0.6974), tensor(1.7682), tensor(1.68...   \n..                                                 ...   \n993  [[[tensor(1.1528), tensor(1.6799), tensor(1.23...   \n995  [[[tensor(0.), tensor(0.), tensor(0.), tensor(...   \n996  [[[tensor(0.0161), tensor(0.), tensor(0.), ten...   \n998  [[[tensor(0.), tensor(0.), tensor(0.), tensor(...   \n999  [[[tensor(0.), tensor(0.0324), tensor(0.6179),...   \n\n                                   AudioEnc_embeddings     length  \n42   [0.020753913, 0.031563073, 0.039239094, 0.8021...  25.000000  \n50   [11.986315, 42.080883, 21.232847, 14.662971, 2...   9.500000  \n60   [0.48990253, 5.3505015, 36.0851, 57.74213, 24....  13.833333  \n63   [419.2322, 527.33276, 226.11122, 109.44811, 11...  12.300000  \n79   [0.66644806, 1.9188691, 0.5836652, 0.13023834,...  50.433333  \n..                                                 ...        ...  \n993  [21.94578, 72.97068, 41.614143, 19.956268, 14....   5.160000  \n995  [157.58481, 179.05833, 24.721344, 20.241692, 1...   7.533333  \n996  [42.9752, 88.70443, 26.27396, 23.015589, 28.37...  27.727728  \n998  [113.20377, 311.62283, 177.75804, 70.84638, 29...  19.500000  \n999  [11.490086, 19.361765, 14.227444, 27.999464, 3...  28.900000  \n\n[289 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>created</th>\n      <th>uuid</th>\n      <th>link</th>\n      <th>video_path</th>\n      <th>embeddings</th>\n      <th>is_duplicate</th>\n      <th>duplicate_for</th>\n      <th>UnetEnc_embeddings</th>\n      <th>AudioEnc_embeddings</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>42</th>\n      <td>2024-06-05 01:53:00</td>\n      <td>fd52cbe5-012f-4451-abad-1c86c8279e8c</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/fd52...</td>\n      <td>C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...</td>\n      <td>[0.0040277336, 0.013641495, 0.007854927, 0.025...</td>\n      <td>True</td>\n      <td>4b005e08-6890-4c4b-b0cf-95dc3e1aabeb</td>\n      <td>[[[tensor(0.), tensor(0.0393), tensor(0.2136),...</td>\n      <td>[0.020753913, 0.031563073, 0.039239094, 0.8021...</td>\n      <td>25.000000</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>2024-06-05 19:13:01</td>\n      <td>6f6f5da8-f997-491d-8fe0-64d262b2ee4c</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/6f6f...</td>\n      <td>C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...</td>\n      <td>[0.028689208, 0.0125948135, 0.005007297, 0.003...</td>\n      <td>True</td>\n      <td>22ee80a3-d9ef-48d4-83d7-9c97cc7030c2</td>\n      <td>[[[tensor(0.), tensor(0.), tensor(1.4099), ten...</td>\n      <td>[11.986315, 42.080883, 21.232847, 14.662971, 2...</td>\n      <td>9.500000</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>2024-06-06 10:04:01</td>\n      <td>cbf3948e-e8a0-4e61-858d-72b7ff2d2d43</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/cbf3...</td>\n      <td>C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...</td>\n      <td>[0.0054139197, 0.009174943, 0.015418697, 0.002...</td>\n      <td>True</td>\n      <td>045265e5-0d4c-4372-b960-3087f685eb97</td>\n      <td>[[[tensor(0.), tensor(0.), tensor(0.), tensor(...</td>\n      <td>[0.48990253, 5.3505015, 36.0851, 57.74213, 24....</td>\n      <td>13.833333</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>2024-06-06 13:46:37</td>\n      <td>89fca4ee-4678-482b-8d6d-907dbc057151</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/89fc...</td>\n      <td>C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...</td>\n      <td>[0.00235023, 0.0231305, 0.005213861, 0.0035420...</td>\n      <td>True</td>\n      <td>2cfd6af3-7df6-4afa-8c3b-c17236c83c03</td>\n      <td>[[[tensor(0.), tensor(0.), tensor(0.1531), ten...</td>\n      <td>[419.2322, 527.33276, 226.11122, 109.44811, 11...</td>\n      <td>12.300000</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>2024-06-07 22:14:03</td>\n      <td>51b077bc-fac3-4cdb-bda4-06cd60d53af7</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/51b0...</td>\n      <td>C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...</td>\n      <td>[0.0065238466, 0.002718225, 0.0021864201, 0.01...</td>\n      <td>True</td>\n      <td>0d62849b-d3b9-47af-a285-2f638bc9ac13</td>\n      <td>[[[tensor(0.6974), tensor(1.7682), tensor(1.68...</td>\n      <td>[0.66644806, 1.9188691, 0.5836652, 0.13023834,...</td>\n      <td>50.433333</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>993</th>\n      <td>2024-09-07 06:04:07</td>\n      <td>7e67cde3-d548-4e7b-b3e1-90c83a4632ed</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/7e67...</td>\n      <td>C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...</td>\n      <td>[0.008075179, 0.016512446, 0.035428133, 0.0115...</td>\n      <td>True</td>\n      <td>4b06ed60-3d36-4537-b351-be9dd28755b7</td>\n      <td>[[[tensor(1.1528), tensor(1.6799), tensor(1.23...</td>\n      <td>[21.94578, 72.97068, 41.614143, 19.956268, 14....</td>\n      <td>5.160000</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>2024-09-07 17:10:54</td>\n      <td>933149f9-e660-4377-95c8-f8dd329db24e</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/9331...</td>\n      <td>C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...</td>\n      <td>[0.015765151, 0.007593849, 0.03509754, 0.01167...</td>\n      <td>True</td>\n      <td>06e0d485-d4e1-4ba7-8eb2-e2f1fcfca416</td>\n      <td>[[[tensor(0.), tensor(0.), tensor(0.), tensor(...</td>\n      <td>[157.58481, 179.05833, 24.721344, 20.241692, 1...</td>\n      <td>7.533333</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>2024-09-08 05:18:24</td>\n      <td>9f707190-3b32-48bf-a5f4-ceec6eedb847</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/9f70...</td>\n      <td>C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...</td>\n      <td>[0.042089663, 0.0043040505, 0.023805328, 0.012...</td>\n      <td>True</td>\n      <td>56cfa0d5-a050-4443-9a80-1403bcad6839</td>\n      <td>[[[tensor(0.0161), tensor(0.), tensor(0.), ten...</td>\n      <td>[42.9752, 88.70443, 26.27396, 23.015589, 28.37...</td>\n      <td>27.727728</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>2024-09-11 04:42:01</td>\n      <td>ef7e175e-2391-45a0-b69f-33837668bb79</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/ef7e...</td>\n      <td>C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...</td>\n      <td>[0.006182716, 0.019054323, 0.032745354, 0.0131...</td>\n      <td>True</td>\n      <td>0574335c-9884-40de-a514-97b3fd3d72df</td>\n      <td>[[[tensor(0.), tensor(0.), tensor(0.), tensor(...</td>\n      <td>[113.20377, 311.62283, 177.75804, 70.84638, 29...</td>\n      <td>19.500000</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>2024-09-12 22:21:33</td>\n      <td>7ed53812-357f-4ad4-bccc-39bb63e27ccb</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/7ed5...</td>\n      <td>C:\\Users\\Vladimir\\PycharmProjects\\ML\\Kaggle\\ya...</td>\n      <td>[0.016747646, 0.003939935, 0.010330777, 0.0043...</td>\n      <td>True</td>\n      <td>3c07e9ae-1796-4bcd-8b12-1ef8a9b61fd5</td>\n      <td>[[[tensor(0.), tensor(0.0324), tensor(0.6179),...</td>\n      <td>[11.490086, 19.361765, 14.227444, 27.999464, 3...</td>\n      <td>28.900000</td>\n    </tr>\n  </tbody>\n</table>\n<p>289 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['is_duplicate']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T04:28:50.112500800Z",
     "start_time": "2024-09-29T04:28:35.574428300Z"
    }
   },
   "id": "1121dfbe2456bfa5"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "              created                                  uuid  \\\n0 2024-06-01 01:37:57  49577a11-51b9-490a-b1f0-df17335219de   \n1 2024-06-01 04:42:10  4e1f7fad-5008-4216-9849-550a00f1e35f   \n2 2024-06-01 08:44:48  337fdbe6-2bc7-4bc7-931e-d94ada927ede   \n3 2024-06-01 10:11:48  35138a88-0249-405e-91b4-8a36b1e2e730   \n4 2024-06-01 12:23:29  322f4312-3d46-401b-8cd9-80a0d06347ed   \n\n                                                link  is_duplicate  \\\n0  https://s3.ritm.media/yappy-db-duplicates/4957...         False   \n1  https://s3.ritm.media/yappy-db-duplicates/4e1f...         False   \n2  https://s3.ritm.media/yappy-db-duplicates/337f...         False   \n3  https://s3.ritm.media/yappy-db-duplicates/3513...         False   \n4  https://s3.ritm.media/yappy-db-duplicates/322f...         False   \n\n  duplicate_for  \n0           NaN  \n1           NaN  \n2           NaN  \n3           NaN  \n4           NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>created</th>\n      <th>uuid</th>\n      <th>link</th>\n      <th>is_duplicate</th>\n      <th>duplicate_for</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2024-06-01 01:37:57</td>\n      <td>49577a11-51b9-490a-b1f0-df17335219de</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/4957...</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2024-06-01 04:42:10</td>\n      <td>4e1f7fad-5008-4216-9849-550a00f1e35f</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/4e1f...</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2024-06-01 08:44:48</td>\n      <td>337fdbe6-2bc7-4bc7-931e-d94ada927ede</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/337f...</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2024-06-01 10:11:48</td>\n      <td>35138a88-0249-405e-91b4-8a36b1e2e730</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/3513...</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2024-06-01 12:23:29</td>\n      <td>322f4312-3d46-401b-8cd9-80a0d06347ed</td>\n      <td>https://s3.ritm.media/yappy-db-duplicates/322f...</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = test[['created', 'uuid', 'link', 'is_duplicate', 'duplicate_for']]\n",
    "sub.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T04:30:06.921856Z",
     "start_time": "2024-09-29T04:30:06.765083Z"
    }
   },
   "id": "10dcbdc3c1c216aa"
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T04:30:42.840036200Z",
     "start_time": "2024-09-29T04:30:42.620926Z"
    }
   },
   "id": "c710608c63cb2421"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bedb395b2df9d660"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
